{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T06:25:30.949804Z",
     "start_time": "2020-03-23T06:25:30.058865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"cn\">\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>Scraping tutorial 1 | 莫烦Python</title>\n",
      "\t<link rel=\"icon\" href=\"https://morvanzhou.github.io/static/img/description/tab_icon.png\">\n",
      "</head>\n",
      "<body>\n",
      "\t<h1>爬虫测试1</h1>\n",
      "\t<p>\n",
      "\t\t这是一个在 <a href=\"https://morvanzhou.github.io/\">莫烦Python</a>\n",
      "\t\t<a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n",
      "\t</p>\n",
      "\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from  urllib.request import urlopen\n",
    "\n",
    "html=urlopen('https://morvanzhou.github.io/static/scraping/basic-structure.html').read().decode('utf-8')\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T07:07:39.221376Z",
     "start_time": "2020-03-23T07:07:39.219374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Scraping tutorial 1 | 莫烦Python']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "res=re.findall(r'<title>(.+?)</title>',html)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T07:07:42.259384Z",
     "start_time": "2020-03-23T07:07:42.256381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t这是一个在 <a href=\"https://morvanzhou.github.io/\">莫烦Python</a>\n",
      "\t\t<a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "res=re.findall(r\"<p>(.+?)</p>\",html,flags=re.DOTALL)\n",
    "# re.DOTALL if multi line\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T07:07:14.048952Z",
     "start_time": "2020-03-23T07:07:14.046924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://morvanzhou.github.io/static/img/description/tab_icon.png', 'https://morvanzhou.github.io/', 'https://morvanzhou.github.io/tutorials/data-manipulation/scraping/']\n"
     ]
    }
   ],
   "source": [
    "res = re.findall(r'href=\"(.*?)\"', html)\n",
    "print( res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T09:14:17.492515Z",
     "start_time": "2020-03-24T09:14:17.001714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"cn\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>Scraping tutorial 1 | 莫烦Python</title>\n",
      "<link href=\"https://morvanzhou.github.io/static/img/description/tab_icon.png\" rel=\"icon\"/>\n",
      "</head>\n",
      "<body>\n",
      "<h1>爬虫测试1</h1>\n",
      "<p>\n",
      "\t\t这是一个在 <a href=\"https://morvanzhou.github.io/\">莫烦Python</a>\n",
      "<a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n",
      "\t</p>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n",
      " <p>\n",
      "\t\t这是一个在 <a href=\"https://morvanzhou.github.io/\">莫烦Python</a>\n",
      "<a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\">爬虫教程</a> 中的简单测试.\n",
      "\t</p>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "html=urlopen(\"https://morvanzhou.github.io/static/scraping/basic-structure.html\").read().decode('utf-8')\n",
    "#print(html)\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(html,features='lxml')\n",
    "print(soup)\n",
    "print('\\n\\n',soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T08:26:49.069370Z",
     "start_time": "2020-03-23T08:26:49.066367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"https://morvanzhou.github.io/\">莫烦Python</a>, <a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\">爬虫教程</a>]\n",
      "https://morvanzhou.github.io/\n",
      "https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\n"
     ]
    }
   ],
   "source": [
    "all_href=soup.find_all('a')\n",
    "print(all_href)\n",
    "for i in all_href:\n",
    "    print(i['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## beautiful 解析 CSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T08:44:56.360453Z",
     "start_time": "2020-03-23T08:44:55.942517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一月\n",
      "二月\n",
      "三月\n",
      "四月\n",
      "五月\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "html=urlopen(\"https://morvanzhou.github.io/static/scraping/list.html\").read().decode('utf-8')\n",
    "\n",
    "soup=BeautifulSoup(html,'lxml')\n",
    "month=soup.find_all('li',{'class':'month'})\n",
    "for m in month :\n",
    "    print(m.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T08:56:21.256545Z",
     "start_time": "2020-03-23T08:56:21.252541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一月一号\n",
      "一月二号\n",
      "一月三号\n"
     ]
    }
   ],
   "source": [
    "jan=soup.find('ul',{'class':'jan'})#注意这里用find，只返回一个不然后报错\n",
    "d_jan=jan.find_all('li')\n",
    "for i in d_jan:\n",
    "    print(i.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beautiful + RegEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:12:13.352836Z",
     "start_time": "2020-03-23T09:12:12.705155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"cn\">\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>爬虫练习 表格 table | 莫烦 Python</title>\n",
      "\n",
      "\t<style>\n",
      "\timg {\n",
      "\t\twidth: 250px;\n",
      "\t}\n",
      "\ttable{\n",
      "\t\twidth:50%;\n",
      "\t}\n",
      "\ttd{\n",
      "\t\tmargin:10px;\n",
      "\t\tpadding:15px;\n",
      "\t}\n",
      "\t</style>\n",
      "</head>\n",
      "<body>\n",
      "\n",
      "<h1>表格 爬虫练习</h1>\n",
      "\n",
      "<p>这是一个在 <a href=\"https://morvanzhou.github.io/\" >莫烦 Python</a> 的 <a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\" >爬虫教程</a>\n",
      "\t里无敌简单的网页, 所有的 code 让你一目了然, 清晰无比.</p>\n",
      "\n",
      "<br>\n",
      "<table id=\"course-list\">\n",
      "\t<tr>\n",
      "\t\t<th>\n",
      "\t\t\t分类\n",
      "\t\t</th><th>\n",
      "\t\t\t名字\n",
      "\t\t</th><th>\n",
      "\t\t\t时长\n",
      "\t\t</th><th>\n",
      "\t\t\t预览\n",
      "\t\t</th>\n",
      "\t</tr>\n",
      "\n",
      "\t<tr id=\"course1\" class=\"ml\">\n",
      "\t\t<td>\n",
      "\t\t\t机器学习\n",
      "\t\t</td><td>\n",
      "\t\t\t<a href=\"https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/\">\n",
      "\t\t\t\tTensorflow 神经网络</a>\n",
      "\t\t</td><td>\n",
      "\t\t\t2:00\n",
      "\t\t</td><td>\n",
      "\t\t\t<img src=\"https://morvanzhou.github.io/static/img/course_cover/tf.jpg\">\n",
      "\t\t</td>\n",
      "\t</tr>\n",
      "\n",
      "\t<tr id=\"course2\" class=\"ml\">\n",
      "\t\t<td>\n",
      "\t\t\t机器学习\n",
      "\t\t</td><td>\n",
      "\t\t\t<a href=\"https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/\">\n",
      "\t\t\t\t强化学习</a>\n",
      "\t\t</td><td>\n",
      "\t\t\t5:00\n",
      "\t\t</td><td>\n",
      "\t\t\t<img src=\"https://morvanzhou.github.io/static/img/course_cover/rl.jpg\">\n",
      "\t\t</td>\n",
      "\t</tr>\n",
      "\n",
      "\t<tr id=\"course3\" class=\"data\">\n",
      "\t\t<td>\n",
      "\t\t\t数据处理\n",
      "\t\t</td><td>\n",
      "\t\t\t<a href=\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\">\n",
      "\t\t\t\t爬虫</a>\n",
      "\t\t</td><td>\n",
      "\t\t\t3:00\n",
      "\t\t</td><td>\n",
      "\t\t\t<img src=\"https://morvanzhou.github.io/static/img/course_cover/scraping.jpg\">\n",
      "\t\t</td>\n",
      "\t</tr>\n",
      "\n",
      "</table>\n",
      "\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "\n",
    "html=urlopen(\"https://morvanzhou.github.io/static/scraping/table.html\").read().decode('utf-8')\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:18:03.782462Z",
     "start_time": "2020-03-23T09:18:03.778458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://morvanzhou.github.io/static/img/course_cover/tf.jpg\n",
      "https://morvanzhou.github.io/static/img/course_cover/rl.jpg\n",
      "https://morvanzhou.github.io/static/img/course_cover/scraping.jpg\n"
     ]
    }
   ],
   "source": [
    "soup=BeautifulSoup(html,'lxml')\n",
    "\n",
    "img_links=soup.find_all('img',{'src':re.compile('.*?\\.jpg')})\n",
    "#加了？表示非贪婪匹配，只匹配条件中第一个，最小匹配\n",
    "\n",
    "for link in img_links:\n",
    "    print(link['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:30:02.025500Z",
     "start_time": "2020-03-23T09:30:02.022497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://morvanzhou.github.io/\n",
      "https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\n",
      "https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/\n",
      "https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/\n",
      "https://morvanzhou.github.io/tutorials/data-manipulation/scraping/\n"
     ]
    }
   ],
   "source": [
    "courses=soup.find_all('a',{'href':re.compile('https://morvanzhou.*')})\n",
    "for c in courses:\n",
    "    print(c['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baidu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:51:16.832045Z",
     "start_time": "2020-03-23T09:51:16.453791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "网络爬虫\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import random\n",
    "\n",
    "base_url='https://baike.baidu.com'\n",
    "his=['/item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/5162711']\n",
    "\n",
    "url=base_url+his[0]\n",
    "html=urlopen(url).read().decode('utf-8')\n",
    "soup=BeautifulSoup(html,'lxml')\n",
    "\n",
    "print(soup.find('h1').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-23T10:45:18.858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 网络爬虫         url:   /item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/5162711\n",
      "1 网络爬虫         url:   /item/%E8%9C%98%E8%9B%9B/8135707\n",
      "2 蚁科         url:   /item/%E8%9A%82%E8%9A%81/9770178\n",
      "3 甲酸         url:   /item/%E7%94%B2%E9%85%B8/1401707\n",
      "4 临界温度         url:   /item/%E4%B8%B4%E7%95%8C%E6%B8%A9%E5%BA%A6/22831\n",
      "5 压强         url:   /item/%E5%8E%8B%E5%BC%BA/1485336\n",
      "6 活塞式抽水机         url:   /item/%E6%B4%BB%E5%A1%9E%E5%BC%8F%E6%8A%BD%E6%B0%B4%E6%9C%BA/1535490\n",
      "7 抽水机         url:   /item/%E6%8A%BD%E6%B0%B4%E6%9C%BA/1535457\n",
      "8 水泵         url:   /item/%E6%B0%B4%E6%B3%B5/4154530\n",
      "9 机械         url:   /item/%E6%9C%BA%E6%A2%B0/68186\n",
      "10 水泵         url:   /item/%E6%B0%B4%E6%B3%B5/4154530\n",
      "11 机械         url:   /item/%E6%9C%BA%E6%A2%B0/68186\n",
      "12 水泵         url:   /item/%E6%B0%B4%E6%B3%B5/4154530\n",
      "13 扬程         url:   /item/%E6%89%AC%E7%A8%8B/143562\n",
      "14 水泵         url:   /item/%E6%B0%B4%E6%B3%B5/4154530\n",
      "15 叶片泵         url:   /item/%E5%8F%B6%E7%89%87%E6%B3%B5/4780158\n",
      "16 水泵         url:   /item/%E6%B0%B4%E6%B3%B5/4154530\n",
      "17 水         url:   /item/%E6%B0%B4/34133\n",
      "18 等离子体         url:   /item/%E7%AD%89%E7%A6%BB%E5%AD%90%E4%BD%93/106920\n",
      "19 导电体         url:   /item/%E5%AF%BC%E7%94%B5%E4%BD%93/4401206\n",
      "20 绝缘体         url:   /item/%E7%BB%9D%E7%BC%98%E4%BD%93/1017293\n",
      "21 电荷         url:   /item/%E7%94%B5%E8%8D%B7/1144574\n",
      "22 静电力         url:   /item/%E7%94%B5%E7%A3%81%E5%8A%9B/2390988\n",
      "23 相互作用力         url:   /item/%E7%9B%B8%E4%BA%92%E4%BD%9C%E7%94%A8%E5%8A%9B/8750748\n",
      "24 基本力         url:   /item/%E5%9F%BA%E6%9C%AC%E5%8A%9B/8840690\n",
      "25 强核力         url:   /item/%E5%BC%BA%E7%9B%B8%E4%BA%92%E4%BD%9C%E7%94%A8%E5%8A%9B/4805768\n",
      "26 短程力         url:   /item/%E7%9F%AD%E7%A8%8B%E5%8A%9B/1009416\n",
      "27 强核力         url:   /item/%E5%BC%BA%E7%9B%B8%E4%BA%92%E4%BD%9C%E7%94%A8%E5%8A%9B/4805768\n",
      "28 π介子         url:   /item/%CF%80%E4%BB%8B%E5%AD%90/4189816\n",
      "29 介子         url:   /item/%E4%BB%8B%E5%AD%90/469911\n",
      "30 基本粒子         url:   /item/%E5%9F%BA%E6%9C%AC%E7%B2%92%E5%AD%90/79521\n",
      "31 轻子         url:   /item/%E8%BD%BB%E5%AD%90/125814\n",
      "32 衰变         url:   /item/%E8%A1%B0%E5%8F%98/483106\n",
      "33 轻子         url:   /item/%E8%BD%BB%E5%AD%90/125814\n",
      "34 衰变         url:   /item/%E8%A1%B0%E5%8F%98/483106\n",
      "35 轻子         url:   /item/%E8%BD%BB%E5%AD%90/125814\n",
      "36 中性粒子         url:   /item/%E4%B8%AD%E6%80%A7%E7%B2%92%E5%AD%90/4195452\n",
      "37 中微子         url:   /item/%E4%B8%AD%E5%BE%AE%E5%AD%90/243111\n",
      "38 意大利         url:   /item/%E6%84%8F%E5%A4%A7%E5%88%A9/148336\n",
      "39 地中海         url:   /item/%E5%9C%B0%E4%B8%AD%E6%B5%B7/11515\n",
      "40 马尔马拉海         url:   /item/%E9%A9%AC%E5%B0%94%E9%A9%AC%E6%8B%89%E6%B5%B7/442924\n",
      "41 克孜勒群岛         url:   /item/%E5%85%8B%E5%AD%9C%E5%8B%92%E7%BE%A4%E5%B2%9B/6784732\n",
      "42 拜占廷帝国         url:   /item/%E6%8B%9C%E5%8D%A0%E5%BA%AD/70649\n",
      "43 狄奥多西一世         url:   /item/%E7%8B%84%E5%A5%A5%E5%A4%9A%E8%A5%BF%E4%B8%80%E4%B8%96/1664721\n",
      "44 基督教         url:   /item/%E5%9F%BA%E7%9D%A3%E6%95%99/222408\n",
      "45 使徒         url:   /item/%E4%BD%BF%E5%BE%92/60437\n",
      "46 耶稣基督         url:   /item/%E8%80%B6%E7%A8%A3%E5%9F%BA%E7%9D%A3/1107299\n",
      "47 新约全书         url:   /item/%E6%96%B0%E7%BA%A6/432750\n",
      "48 上帝         url:   /item/%E4%B8%8A%E5%B8%9D/8166375\n",
      "49 通典         url:   /item/%E9%80%9A%E5%85%B8/10812740\n",
      "50 纪传体         url:   /item/%E7%BA%AA%E4%BC%A0%E4%BD%93/914490\n",
      "51 何乔远         url:   /item/%E4%BD%95%E4%B9%94%E8%BF%9C/3732454\n",
      "52 方志         url:   /item/%E6%96%B9%E5%BF%97/10562\n",
      "53 禹         url:   /item/%E5%A4%8F%E7%A6%B9/5471617\n",
      "54 秦始皇         url:   /item/%E7%A7%A6%E5%A7%8B%E7%9A%87/6164\n",
      "55 秦时明月         url:   /item/%E7%A7%A6%E6%97%B6%E6%98%8E%E6%9C%88/5285257\n",
      "56 倚天屠龙记         url:   /item/%E5%80%9A%E5%A4%A9%E5%B1%A0%E9%BE%99%E8%AE%B0/5683\n",
      "57 蒋家骏         url:   /item/%E8%92%8B%E5%AE%B6%E9%AA%8F/12081\n",
      "58 第十届中美电影节         url:   /item/%E7%AC%AC%E5%8D%81%E5%B1%8A%E4%B8%AD%E7%BE%8E%E7%94%B5%E5%BD%B1%E8%8A%82/15864974\n",
      "59 中国合伙人         url:   /item/%E4%B8%AD%E5%9B%BD%E5%90%88%E4%BC%99%E4%BA%BA/10191907\n",
      "60 佟大为         url:   /item/%E4%BD%9F%E5%A4%A7%E4%B8%BA/282364\n",
      "61 都是天使惹的祸         url:   /item/%E9%83%BD%E6%98%AF%E5%A4%A9%E4%BD%BF%E6%83%B9%E7%9A%84%E7%A5%B8/3404935\n",
      "62 郭涛         url:   /item/%E9%83%AD%E6%B6%9B/5894\n",
      "63 亲密爱人         url:   /item/%E4%BA%B2%E5%AF%86%E7%88%B1%E4%BA%BA/526498\n",
      "64 刘孜         url:   /item/%E5%88%98%E5%AD%9C/70712\n",
      "65 我这一辈子         url:   /item/%E6%88%91%E8%BF%99%E4%B8%80%E8%BE%88%E5%AD%90/775408\n",
      "66 何冰         url:   /item/%E4%BD%95%E5%86%B0/8609\n",
      "67 大宋提刑官         url:   /item/%E5%A4%A7%E5%AE%8B%E6%8F%90%E5%88%91%E5%AE%98/2819138\n"
     ]
    }
   ],
   "source": [
    "#找出href中满足/item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB类型的\n",
    "sub_urls=soup.find_all('a',{'target':'_blank','href':re.compile('/item/(%.{2})+/(\\d)+$')})\n",
    "\n",
    "his=['/item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/5162711']\n",
    "\n",
    "for i in range(200):\n",
    "    url=base_url+his[-1]\n",
    "    \n",
    "    html=urlopen(url).read().decode('utf-8')\n",
    "    soup=BeautifulSoup(html,'lxml')\n",
    "    print(i,soup.find('h1').get_text(),'        url:  ',his[-1])\n",
    "    sub_urls=soup.find_all('a',{'target':'_blank','href':re.compile('/item/(%.{2})+/(\\d)+$')})\n",
    "    \n",
    "    if len(sub_urls)!=0:\n",
    "        his.append(random.sample(sub_urls,1)[0]['href'])\n",
    "    \n",
    "    else:\n",
    "        his.pop()#默认删除最后一条\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:04:43.973358Z",
     "start_time": "2020-03-24T08:04:43.706941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wappass.baidu.com/static/captcha/tuxing.html?&ak=c27bbc89afca0463650ac9bde68ebe06&backurl=https%3A%2F%2Fwww.baidu.com%2Fs%3Fwd%3D%25E8%258E%25AB%25E7%2583%25A6Python&logid=8060159739553071862&signature=81734947f5bf5049d6223d0a95f9f119&timestamp=1585037085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import webbrowser\n",
    "\n",
    "param={'wd':'莫烦Python'}\n",
    "r=requests.get('http://www.baidu.com/s',params=param)\n",
    "print(r.url)\n",
    "webbrowser.open(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post  上传"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:11:16.586672Z",
     "start_time": "2020-03-24T08:11:16.019561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there, aaa bbb!\n"
     ]
    }
   ],
   "source": [
    "data={'firstname':'aaa','lastname':'bbb'}\n",
    "r=requests.post('http://pythonscraping.com/pages/files/processing.php',data=data)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upload image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:22:05.523813Z",
     "start_time": "2020-03-24T08:22:03.790988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploads/timg.jpg\n",
      "The file timg.jpg has been uploaded.\n"
     ]
    }
   ],
   "source": [
    "file={'uploadFile':open(r'C:\\Users\\a\\Desktop\\Fish\\timg.jpg','rb')}\n",
    "r=requests.post('http://pythonscraping.com/pages/files/processing2.php',files=file)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Login  cookies/session 持续登录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:36:08.306549Z",
     "start_time": "2020-03-24T08:36:04.350052Z"
    }
   },
   "outputs": [],
   "source": [
    "payload={'username':'aaa','password':'password'}\n",
    "r=requests.post('http://pythonscraping.com/pages/cookies/welcome.php',data=payload)\n",
    "print(r.cookies.get_dict())\n",
    "r=requests.get('http://pythonscraping.com/pages/cookies/profile.php',cookies=r.cookies)\n",
    "print(r.text)\n",
    "\n",
    "\n",
    "#another way \n",
    "session=requests.Session()\n",
    "payload={'username':'aaa','password':'password'}\n",
    "r=session.post('http://pythonscraping.com/pages/cookies/welcome.php',data=payload)\n",
    "print(r.cookies.get_dict())\n",
    "r=session.get('http://pythonscraping.com/pages/cookies/profile.php')\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:51:04.553893Z",
     "start_time": "2020-03-24T08:51:04.549889Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(r'C:\\Users\\a\\Desktop\\img',exist_ok=True)\n",
    "IMG_URL='https://morvanzhou.github.io/static/img/description/learning_step_flowchart.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:51:36.093510Z",
     "start_time": "2020-03-24T08:51:34.905861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\a\\\\Desktop\\\\img\\\\img1.jpg',\n",
       " <http.client.HTTPMessage at 0x20fb37fd630>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#method 1\n",
    "from urllib.request import urlretrieve\n",
    "urlretrieve(IMG_URL,r'C:\\Users\\a\\Desktop\\img\\img1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:53:34.287146Z",
     "start_time": "2020-03-24T08:53:33.273712Z"
    }
   },
   "outputs": [],
   "source": [
    "#method 2\n",
    "#全部下载再保存\n",
    "import requests\n",
    "r=requests.get(IMG_URL)\n",
    "with open(r'C:\\Users\\a\\Desktop\\img\\img2.jpg','wb')as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:57:47.978057Z",
     "start_time": "2020-03-24T08:57:46.966970Z"
    }
   },
   "outputs": [],
   "source": [
    "#method 3\n",
    "#用stream ，边下载边存，效率更高，适用于大文件\n",
    "#通过chunk的形式\n",
    "\n",
    "r=requests.get(IMG_URL,stream=True)\n",
    "with open(r'C:\\Users\\a\\Desktop\\img\\img4.jpg','wb')as f:\n",
    "    for chunk in r.iter_content(chunk_size=64):\n",
    "        f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 国家地理下载图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T09:22:30.121289Z",
     "start_time": "2020-03-24T09:22:09.577494Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved  20200323023856815.jpg\n",
      "Saved  20200320013442494.jpg\n",
      "Saved  20200313022516666.jpg\n",
      "Saved  20200313104903928.jpg\n",
      "Saved  20200310052836354.jpg\n",
      "Saved  20200310022744749.jpg\n"
     ]
    }
   ],
   "source": [
    "from bs4 import  BeautifulSoup\n",
    "import requests\n",
    "\n",
    "URL='http://www.ngchina.com.cn/animals/'\n",
    "\n",
    "\n",
    "#找到图片位置\n",
    "html=requests.get(URL).text\n",
    "soup=BeautifulSoup(html,'lxml')\n",
    "img_url=soup.find_all('ul',{'class':'img_list'})\n",
    "\n",
    "#download\n",
    "for ul in img_url:\n",
    "    imgs=ul.find_all('img')\n",
    "    for img in imgs:\n",
    "        url=img['src']\n",
    "        r=requests.get(url,stream=True)\n",
    "        image_name=url.split('/')[-1]#url用/分开，选最后一个\n",
    "        with open(r'C:\\Users\\a\\Desktop\\img\\%s'%image_name,'wb')as f:\n",
    "            for chunk in r.iter_content(chunk_size=128):\n",
    "                f.write(chunk)\n",
    "        print('Saved  %s' % image_name)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
